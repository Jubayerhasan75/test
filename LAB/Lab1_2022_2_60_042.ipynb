{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 14627227,
          "sourceType": "datasetVersion",
          "datasetId": 9343468
        }
      ],
      "dockerImageVersionId": 31259,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "Lab1_2022-2-60-042",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jubayerhasan75/test/blob/main/LAB/Lab1_2022_2_60_042.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "KWlacyijFzXQ"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "jubayerhasan755_mushroom_path = kagglehub.dataset_download('jubayerhasan755/mushroom')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "4eg-ITdKFzXS"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-26T15:49:12.865128Z",
          "iopub.execute_input": "2026-01-26T15:49:12.866084Z",
          "iopub.status.idle": "2026-01-26T15:49:12.8713Z",
          "shell.execute_reply.started": "2026-01-26T15:49:12.866045Z",
          "shell.execute_reply": "2026-01-26T15:49:12.870372Z"
        },
        "id": "K24B-BZ7FzXT"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
      ],
      "metadata": {
        "id": "a_XkuVNLIFhM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Specific Kaggle Path\n",
        "path = '/kaggle/input/mushroom/agaricus-lepiota.data'\n",
        "\n",
        "# Standard column names for the UCI Mushroom dataset\n",
        "columns = [\n",
        "    \"class\", \"cap-shape\", \"cap-surface\", \"cap-color\", \"bruises\", \"odor\",\n",
        "    \"gill-attachment\", \"gill-spacing\", \"gill-size\", \"gill-color\",\n",
        "    \"stalk-shape\", \"stalk-root\", \"stalk-surface-above-ring\",\n",
        "    \"stalk-surface-below-ring\", \"stalk-color-above-ring\",\n",
        "    \"stalk-color-below-ring\", \"veil-type\", \"veil-color\", \"ring-number\",\n",
        "    \"ring-type\", \"spore-print-color\", \"population\", \"habitat\"\n",
        "]\n",
        "\n",
        "# Load the data\n",
        "df = pd.read_csv(path, header=None, names=columns)\n",
        "\n",
        "print(\"Data Loaded Successfully!\")\n",
        "print(f\"Dataset Shape: {df.shape}\")\n",
        "df.head()\n",
        "print(\"\\nClass Distribution:\\n\", df['class'].value_counts())\n",
        "\n",
        "# Check for missing values\n",
        "print(\"\\nMissing Values:\\n\", df.isnull().sum().sum())\n",
        "print(df)\n",
        "\n",
        "# Check for missing values\n",
        "print(\"\\nMissing Values:\\n\", df.isnull().sum().sum())"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-26T15:49:12.873042Z",
          "iopub.execute_input": "2026-01-26T15:49:12.873434Z",
          "iopub.status.idle": "2026-01-26T15:49:12.940396Z",
          "shell.execute_reply.started": "2026-01-26T15:49:12.873405Z",
          "shell.execute_reply": "2026-01-26T15:49:12.939303Z"
        },
        "id": "8AxUEer7FzXT"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "le = LabelEncoder()\n",
        "df_encoded = df.apply(le.fit_transform)\n",
        "plt.figure(figsize=(15, 12))\n",
        "sns.heatmap(df_encoded.corr(), annot=True, fmt=\".1f\", cmap='coolwarm')\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-26T15:49:12.941588Z",
          "iopub.execute_input": "2026-01-26T15:49:12.941926Z",
          "iopub.status.idle": "2026-01-26T15:49:13.956181Z",
          "shell.execute_reply.started": "2026-01-26T15:49:12.941888Z",
          "shell.execute_reply": "2026-01-26T15:49:13.955336Z"
        },
        "id": "j7Y73yWgFzXU"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(6,4))\n",
        "sns.countplot(x='class', data=df, palette='viridis')\n",
        "plt.title('Distribution of Edible vs Poisonous Mushrooms')\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-26T15:49:13.958133Z",
          "iopub.execute_input": "2026-01-26T15:49:13.958462Z",
          "iopub.status.idle": "2026-01-26T15:49:14.123287Z",
          "shell.execute_reply.started": "2026-01-26T15:49:13.958434Z",
          "shell.execute_reply": "2026-01-26T15:49:14.122169Z"
        },
        "id": "Na-g-9frFzXU"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "le = LabelEncoder()\n",
        "for col in df.columns:\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "\n",
        "X = df.drop('class', axis=1).values\n",
        "y = df['class'].values.reshape(-1, 1)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# --- Manual Decision Tree Implementation ---\n",
        "class Node:\n",
        "    def __init__(self, feature_index=None, threshold=None, left=None, right=None, info_gain=None, value=None):\n",
        "        self.feature_index = feature_index\n",
        "        self.threshold = threshold\n",
        "        self.left = left\n",
        "        self.right = right\n",
        "        self.info_gain = info_gain\n",
        "        self.value = value\n",
        "\n",
        "class ManualDecisionTree:\n",
        "    def __init__(self, min_samples_split=2, max_depth=5):\n",
        "        self.root = None\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.max_depth = max_depth\n",
        "\n",
        "    def build_tree(self, dataset, curr_depth=0):\n",
        "        X, y = dataset[:, :-1], dataset[:, -1]\n",
        "        num_samples, num_features = np.shape(X)\n",
        "\n",
        "        if num_samples >= self.min_samples_split and curr_depth <= self.max_depth:\n",
        "            best_split = self.get_best_split(dataset, num_samples, num_features)\n",
        "            if best_split[\"info_gain\"] > 0:\n",
        "                left_subtree = self.build_tree(best_split[\"dataset_left\"], curr_depth + 1)\n",
        "                right_subtree = self.build_tree(best_split[\"dataset_right\"], curr_depth + 1)\n",
        "                return Node(best_split[\"feature_index\"], best_split[\"threshold\"], left_subtree, right_subtree, best_split[\"info_gain\"])\n",
        "\n",
        "        return Node(value=self.calculate_leaf_value(y))\n",
        "\n",
        "    def get_best_split(self, dataset, num_samples, num_features):\n",
        "        best_split = {\"info_gain\": -float(\"inf\")}\n",
        "        for feature_index in range(num_features):\n",
        "            feature_values = dataset[:, feature_index]\n",
        "            possible_thresholds = np.unique(feature_values)\n",
        "            for threshold in possible_thresholds:\n",
        "                dataset_left, dataset_right = self.split(dataset, feature_index, threshold)\n",
        "                if len(dataset_left) > 0 and len(dataset_right) > 0:\n",
        "                    y_parent, left_y, right_y = dataset[:, -1], dataset_left[:, -1], dataset_right[:, -1]\n",
        "                    curr_info_gain = self.information_gain(y_parent, left_y, right_y)\n",
        "                    if curr_info_gain > best_split[\"info_gain\"]:\n",
        "                        best_split = {\n",
        "                            \"feature_index\": feature_index,\n",
        "                            \"threshold\": threshold,\n",
        "                            \"dataset_left\": dataset_left,\n",
        "                            \"dataset_right\": dataset_right,\n",
        "                            \"info_gain\": curr_info_gain\n",
        "                        }\n",
        "        return best_split\n",
        "\n",
        "    def split(self, dataset, feature_index, threshold):\n",
        "        dataset_left = np.array([r for r in dataset if r[feature_index] <= threshold])\n",
        "        dataset_right = np.array([r for r in dataset if r[feature_index] > threshold])\n",
        "        return dataset_left, dataset_right\n",
        "\n",
        "    def information_gain(self, parent, l_child, r_child):\n",
        "        w_l, w_r = len(l_child) / len(parent), len(r_child) / len(parent)\n",
        "        return self.entropy(parent) - (w_l * self.entropy(l_child) + w_r * self.entropy(r_child))\n",
        "\n",
        "    def entropy(self, y):\n",
        "        labels = np.unique(y)\n",
        "        ent = 0\n",
        "        for cls in labels:\n",
        "            p_cls = len(y[y == cls]) / len(y)\n",
        "            ent += -p_cls * np.log2(p_cls)\n",
        "        return ent\n",
        "\n",
        "    def calculate_leaf_value(self, y):\n",
        "        y = list(y)\n",
        "        return max(y, key=y.count)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        dataset = np.concatenate((X, y), axis=1)\n",
        "        self.root = self.build_tree(dataset)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return [self.make_prediction(x, self.root) for x in X]\n",
        "\n",
        "    def make_prediction(self, x, tree):\n",
        "        if tree.value is not None: return tree.value\n",
        "        feature_val = x[tree.feature_index]\n",
        "        if feature_val <= tree.threshold:\n",
        "            return self.make_prediction(x, tree.left)\n",
        "        else:\n",
        "            return self.make_prediction(x, tree.right)\n",
        "\n",
        "# --- Model Execution ---\n",
        "dt_manual = ManualDecisionTree(max_depth=5)\n",
        "dt_manual.fit(X_train, y_train)\n",
        "y_pred_manual = dt_manual.predict(X_test)\n",
        "print(f\"Manual Decision Tree Accuracy: {accuracy_score(y_test, y_pred_manual):.4f}\")\n",
        "\n",
        "# --- Random Forest Comparison ---\n",
        "n_estimators_list = [1, 50, 100, 150, 200, 250]\n",
        "rf_accuracies = []\n",
        "y_train_flat = y_train.ravel()\n",
        "\n",
        "for n in n_estimators_list:\n",
        "    rf = RandomForestClassifier(n_estimators=n, random_state=42)\n",
        "    rf.fit(X_train, y_train_flat)\n",
        "    acc = accuracy_score(y_test, rf.predict(X_test))\n",
        "    rf_accuracies.append(acc)\n",
        "    print(f\"RF n_estimators {n}: Accuracy {acc:.4f}\")\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(n_estimators_list, rf_accuracies, marker='o', linestyle='--', color='red')\n",
        "plt.xlabel('n_estimators')\n",
        "plt.ylabel('Accuracy Score')\n",
        "plt.title('RF Accuracy Comparison')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-26T15:49:14.124327Z",
          "iopub.execute_input": "2026-01-26T15:49:14.124606Z",
          "iopub.status.idle": "2026-01-26T15:49:19.661441Z",
          "shell.execute_reply.started": "2026-01-26T15:49:14.124572Z",
          "shell.execute_reply": "2026-01-26T15:49:19.660229Z"
        },
        "id": "5qc24XEVFzXU"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Final Model Comparison**"
      ],
      "metadata": {
        "id": "qJb0yWDNFzXV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "manual_dt_accuracy = accuracy_score(y_test, y_pred_manual)\n",
        "\n",
        "best_rf_accuracy = max(rf_accuracies)\n",
        "\n",
        "print(\"\\n\" + \"=\"*40)\n",
        "print(\"       FINAL MODEL COMPARISON\")\n",
        "print(\"=\"*40)\n",
        "print(f\"Manual Decision Tree Accuracy: {manual_dt_accuracy:.4f}\")\n",
        "print(f\"Best Random Forest Accuracy:   {best_rf_accuracy:.4f}\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "\n",
        "if best_rf_accuracy > manual_dt_accuracy:\n",
        "    diff = best_rf_accuracy - manual_dt_accuracy\n",
        "    print(f\"Winner: Random Forest (Better by {diff:.4f})\")\n",
        "elif manual_dt_accuracy > best_rf_accuracy:\n",
        "    diff = manual_dt_accuracy - best_rf_accuracy\n",
        "    print(f\"Winner: Manual Decision Tree (Better by {diff:.4f})\")\n",
        "else:\n",
        "    print(\"Result: Both models performed equally well!\")\n",
        "\n",
        "print(\"=\"*40)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-26T15:49:19.662943Z",
          "iopub.execute_input": "2026-01-26T15:49:19.663226Z",
          "iopub.status.idle": "2026-01-26T15:49:19.675122Z",
          "shell.execute_reply.started": "2026-01-26T15:49:19.6632Z",
          "shell.execute_reply": "2026-01-26T15:49:19.673636Z"
        },
        "id": "iLWorBbYFzXW"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Confusion Matrix**"
      ],
      "metadata": {
        "id": "6R6ygT-5FzXX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# 1. Generate Confusion Matrices\n",
        "# Manual Decision Tree\n",
        "cm_manual_dt = confusion_matrix(y_test, y_pred_manual)\n",
        "\n",
        "# Random Forest\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "cm_rf = confusion_matrix(y_test, y_pred_rf)\n",
        "\n",
        "# 2. Plotting Side-by-Side\n",
        "fig, ax = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Manual Decision Tree Plot\n",
        "sns.heatmap(cm_manual_dt, annot=True, fmt='d', cmap='Blues', ax=ax[0])\n",
        "ax[0].set_title('Confusion Matrix: Manual Decision Tree')\n",
        "ax[0].set_xlabel('Predicted Label')\n",
        "ax[0].set_ylabel('True Label')\n",
        "ax[0].set_xticklabels(['Edible', 'Poisonous'])\n",
        "ax[0].set_yticklabels(['Edible', 'Poisonous'])\n",
        "\n",
        "# Random Forest Plot\n",
        "sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Greens', ax=ax[1])\n",
        "ax[1].set_title(f'Confusion Matrix: Random Forest (n={n})')\n",
        "ax[1].set_xlabel('Predicted Label')\n",
        "ax[1].set_ylabel('True Label')\n",
        "ax[1].set_xticklabels(['Edible', 'Poisonous'])\n",
        "ax[1].set_yticklabels(['Edible', 'Poisonous'])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 3. Print Summary Stats\n",
        "print(\"\\n--- Error Analysis ---\")\n",
        "print(f\"Manual DT False Positives (Danger!): {cm_manual_dt[0][1]}\")\n",
        "print(f\"Random Forest False Positives (Danger!): {cm_rf[0][1]}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-26T15:49:19.676316Z",
          "iopub.execute_input": "2026-01-26T15:49:19.676611Z",
          "iopub.status.idle": "2026-01-26T15:49:20.170197Z",
          "shell.execute_reply.started": "2026-01-26T15:49:19.676586Z",
          "shell.execute_reply": "2026-01-26T15:49:20.169316Z"
        },
        "id": "Oiewh9blFzXX"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}